{"cells":[{"cell_type":"markdown","source":["# Retail Data Analysis using Apache Spark on Databricks Community Edition\nIn this notebook, I will be demonstrating various concepts of Apache Spark such as transformations and actions. I will be executing the examples using various API's present in Apache Spark such as RDD's.\n\nThe notebook is written and executed on Databricks Community Edition. Getting started with Databricks community edition can be found <a href=\"https://docs.databricks.com/user-guide/index.html\">here</a>. Introduction to Apache Spark with Databricks can be found <a href=\"https://docs.databricks.com/spark/latest/training/index.html\">here</a>\n\n### Datasets\n\n1. <a href=\"https://github.com/shwetabhartia/data/tree/master/retail_db/orders.csv\"><b>orders.csv</b></a> - Contains the list of orders. The various attributes present in the dataset are\n 1. Order ID : The unique identifier for the each order (INTEGER)\n 2. Order Date: The date and time when order was placed (DATETIME)\n 3. Customer ID : The customer Id of the customer associated to the order (INTEGER)\n 4. Order Status : The status associated with the order (VARCHAR)\n2. <a href=\"https://github.com/shwetabhartia/data/tree/master/retail_db/order_items.csv\"> <b>order_items.csv</b></a> - Contains the details about the each item ordered in the order list\n 1. Order Item ID: The unique identifier of the each item in the order list(INTEGER)\n 2. Order Item Order ID : The identifier for the order (INTEGER)\n 3. Order Item Product ID : The id associated with the product (INTEGER)\n 4. Order Item Quantity : The quantity ordered for a particular item (INTEGER)\n 5. Order Item Subtotal: The total price for the ordered items (FLOAT)\n 6. Order Item Product Price: The price associated with the each product (FLOAT)\n3. <a href=\"https://github.com/shwetabhartia/data/tree/master/retail_db/products.csv\"> <b>products.csv</b></a> - Contains the details about the each product\n 1. Product ID: The unique identifier for the each product (INTEGER)\n 2. Product Category ID : The identifier for the category to which product belongs (INTEGER)\n 3. Product Description : The description associated with the product (VARCHAR)\n 4. Product Price : The price of the product (FLOAT)\n 5. Product Image : The url of the image associated with the product (VARCHAR)\n4. <a href=\"https://github.com/shwetabhartia/data/tree/master/retail_db/categories.csv\"> <b>categories.csv</b></a> - Contains the details about the each product\n 1. Category ID: The unique identifier for the each category (INTEGER)\n 2. Category Department ID : The identifier for the department to which category belongs (INTEGER)\n 3. Category Name : The name of the category (VARCHAR)"],"metadata":{}},{"cell_type":"markdown","source":["### Downloading the datasets\n\nDownload the datasets using the shell command wget and the URL, save them into the tmp directory. The URL's for the datasets are\n1. orders.csv : https://github.com/shwetabhartia/data/tree/master/retail_db/orders.csv\n2. order_items.csv : https://github.com/shwetabhartia/data/tree/master/retail_db/order_items.csv\n3. products.csv : https://github.com/shwetabhartia/data/tree/master/retail_db/products.csv\n4. category.csv : https://github.com/shwetabhartia/data/tree/master/retail_db/categories.csv"],"metadata":{}},{"cell_type":"code","source":["%sh\nwget -P /tmp \"https://raw.githubusercontent.com/shwetabhartia/data/master/retail_db/orders.csv\"\nwget -P /tmp \"https://raw.githubusercontent.com/shwetabhartia/data/master/retail_db/order_items.csv\"\nwget -P /tmp \"https://raw.githubusercontent.com/shwetabhartia/data/master/retail_db/products.csv\"\nwget -P /tmp \"https://raw.githubusercontent.com/shwetabhartia/data/master/retail_db/categories.csv\""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["### Uploading the datasets into Databricks file system\n\nDatabricks file system is a distributed file system lying on top of Amazon S3. We will upload the data from the local file system into our DBFS. Below is a python script which copies the data from the local file system into the datasets folder of DBFS of your cluster.\n\nNote: The local files are referenced using `file:/` and DBFS files are referenced using `dbfs:/`"],"metadata":{}},{"cell_type":"code","source":["localOrderFilePath = \"file:/tmp/orders.csv\"\nlocalOrderItemFilePath = \"file:/tmp/order_items.csv\"\nlocalProductFilePath = \"file:/tmp/products.csv\"\nlocalCategoriesFilePath = \"file:/tmp/categories.csv\"\ndbutils.fs.mkdirs(\"dbfs:/datasets\")\ndbutils.fs.cp(localOrderFilePath, \"dbfs:/datasets/\")\ndbutils.fs.cp(localOrderItemFilePath, \"dbfs:/datasets\")\ndbutils.fs.cp(localProductFilePath, \"dbfs:/datasets/\")\ndbutils.fs.cp(localCategoriesFilePath, \"dbfs:/datasets\")\n#Displaying the files present in the DBFS datasets folder of your cluser\ndisplay(dbutils.fs.ls(\"dbfs:/datasets\"))"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["### Lambda Function\n\nPython supports the creation of anonymous functions (i.e. functions that are not bound to a name) at runtime, using a construct called \"lambda\"\n\nMore info on <a href=\"http://www.secnetix.de/olli/Python/lambda_functions.hawk\">lambda</a>"],"metadata":{}},{"cell_type":"markdown","source":["### Creating RDD for orders table"],"metadata":{}},{"cell_type":"code","source":["ordersRDD = sc.textFile(\"dbfs:/datasets/orders.csv\")\nfor i in ordersRDD.take(10): print(i)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["### Creating RDD for the order_items table"],"metadata":{}},{"cell_type":"code","source":["orderItemsRDD = sc.textFile(\"dbfs:/datasets/order_items.csv\")\nfor i in orderItemsRDD.take(10): print(i)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["### Creating RDD for the products table"],"metadata":{}},{"cell_type":"code","source":["productsRDD = sc.textFile(\"dbfs:/datasets/products.csv\")\nfor i in productsRDD.take(10): print(i)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["### Creating RDD for the categories table"],"metadata":{}},{"cell_type":"code","source":["categoryRDD = sc.textFile(\"dbfs:/datasets/categories.csv\")\nfor i in categoryRDD.take(10): print(i)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["### Getting the revenue from order_items on daily basis\n1. \"Map\" through the orders RDD and stored order ID and order date in the RDD\n2. \"Map\" through the order items RDD and stored order ID and price\n3. Joined both the RDD based on order ID\n4. Summed the total price for each date and sorted by the revenue\n5. Printed first 10 revenues"],"metadata":{}},{"cell_type":"code","source":["ordersMapRDD = ordersRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[0], x[1]))\norderItemsMapRDD = orderItemsRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[1], float(x[4])))\nordersJoin = ordersMapRDD.join(orderItemsMapRDD)\nrevenuePerDay=ordersJoin.map(lambda x:(x[1][0],x[1][1])).reduceByKey(lambda acc, val:acc+val).map(lambda (x,y):(y,x)).sortByKey().map(lambda (x,y):(y,x))\nfor i in revenuePerDay.take(10): print i\n"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["### Get the number of orders from order_items on daily basis\n1. \"Map\" through the orders RDD and stored order date in the RDD\n2. Created tuple with order date and 1\n3. Added the total orders for each date\n4. Printed first 10 orders per day"],"metadata":{}},{"cell_type":"code","source":["ordersPerDay=ordersRDD.map(lambda x:x.split(',')[1]).map(lambda x:(x,1)).reduceByKey(lambda acc,value:acc+value).sortByKey()\nfor i in ordersPerDay.take(10) : print i"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["### Get total revenue from order_items\n1. \"Map\" through the orders items RDD and stored price in the RDD\n2. Added the total price\n3. Printed total revenue"],"metadata":{}},{"cell_type":"code","source":["totalRevenue=orderItemsRDD.map(lambda x:float(x.split(',')[4])).reduce(lambda acc,value:acc+value)\nprint totalRevenue"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["### Get max priced product in products table\n1. \"Map\" through the products RDD and check for the max price of the product\n2. Printed max priced product"],"metadata":{}},{"cell_type":"code","source":["maxPricedProduct=productsRDD.map(lambda x:x.split(',')).reduce(lambda rec1,rec2: rec1 if float(rec1[3])>float(rec2[3]) else rec2)\nprint maxPricedProduct"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["### Computing average revenue\n1. \"Map\" through the order items RDD, stored total price and computed revenue\n2. \"Map\" through the order RDD and counted total number of orders\n3. Computed average revenue\n4. Printed average revenue"],"metadata":{}},{"cell_type":"code","source":["totalRevenue=orderItemsRDD.map(lambda x:float(x.split(',')[4])).reduce(lambda acc,value:acc+value)\ntotalDistinctOrders=ordersRDD.map(lambda x:x.split(',')[0]).distinct().count()\naverageRevenue=totalRevenue/totalDistinctOrders\nprint averageRevenue\n"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["### Number of orders by status - Using countByKey\n1. \"Map\" through the orders RDD and stored order status\n2. Computed total orders by status using countByKey\n4. Printed number of orders by status"],"metadata":{}},{"cell_type":"code","source":["#Since countByKey takes in a PairRDD, you have to specify the None, or else it will be taken as a RDD\nordersByStatus = ordersRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[3], None)).countByKey()\nfor i in ordersByStatus.items(): print(i)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["### Number of orders by status - Using groupByKey\n1. \"Map\" through the orders RDD and stored order status\n2. Computed total orders by status using groupByKey\n4. Printed number of orders by status"],"metadata":{}},{"cell_type":"code","source":["ordersGrouped = ordersRDD.map(lambda x: (x.split(\",\")[3],1)).groupByKey().map(lambda (x,y): (x,sum(y)))\nfor i in ordersGrouped.take(10): print(i)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["### Number of orders by status - Using reduceByKey\n1. \"Map\" through the orders RDD and stored order status\n2. Computed total orders by status using reduceByKey\n4. Printed number of orders by status"],"metadata":{}},{"cell_type":"code","source":["ordersByStatus=ordersRDD.map(lambda x: (x.split(\",\")[3],1)).reduceByKey(lambda acc,val: acc+val)\nfor i in ordersByStatus.take(10): print(i)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":["### Get customer_id with max revenue for each day\n1. \"Map\" through the orders RDD and stored order ID as key and date and customer ID as value\n2. \"Map\" through the order items RDD and store order ID and price\n3. Joined both the RDD on order ID\n4. Compared each record to find the customer ID having maximum revenue for each day\n4. Printed customer with max revenue for each day"],"metadata":{}},{"cell_type":"code","source":["ordersMapRDD=ordersRDD.map(lambda x: x.split(',')).map(lambda x: (x[0],(x[1],int(x[2]))))\norderItemsMapRDD=orderItemsRDD.map(lambda x: x.split(',')).map(lambda x: (x[1],float(x[4])))\nordersJoin=ordersMapRDD.join(orderItemsMapRDD)\nperDayRDD=ordersJoin.map(lambda (key,value):(value[0][0],(value[1],value[0][1])))\ncustIdMaxRev=perDayRDD.reduceByKey(lambda x,y: (x if x[1]>y[1] else y))\nfor i in custIdMaxRev.take(10): print i"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":["### Get all the orders with status COMPLETE\n1. \"Map\" through the orders RDD and filtered out order having complete status\n2. Printed number of orders with complete status"],"metadata":{}},{"cell_type":"code","source":["completedOrders = ordersRDD.map(lambda x: x.split(\",\")).filter(lambda x: x[3]==\"COMPLETE\")\nfor i in completedOrders.take(1): print(i)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":["### Get all the orders where status contains the word PENDING\n1. \"Map\" through the orders RDD and filtered out order having pending status\n2. Printed number of orders with pending status"],"metadata":{}},{"cell_type":"code","source":["pendingInOrders = ordersRDD.map(lambda x: x.split(\",\")).filter(lambda x: \"PENDING\" in x[3])\nfor i in pendingInOrders.take(1): print(i)"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":["### Get all the orders where order_id > 100 or order_status is in one of the pending states\n1. \"Map\" through the orders RDD and filtered out order having pending status or order ID > 100\n2. Printed number of orders with pending status and order ID > 100"],"metadata":{}},{"cell_type":"code","source":["filteredRDD = ordersRDD.map(lambda x: x.split(\",\")).filter(lambda x: int(x[0])>100 or \"PENDING\" in x[3])\nfor i in filteredRDD.take(1): print(i)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":["### Check if there are cancelled orders with amount greater than 1000$\n1. \"Map\" through the orders RDD and filtered out order having canceled status and stored order ID, order status\n2. \"Map\" through the orders items RDD and stored order ID, price\n3. Summed all the orders on order ID and filtered out order having total amount > 1000$\n2. Printed number of orders with cancelled status and total order amount > 1000"],"metadata":{}},{"cell_type":"code","source":["cancelledOrders=ordersRDD.map(lambda x:x.split(',')).filter(lambda x : x[3]==\"CANCELED\").map(lambda x: (x[0],x[3]))\nitemGreater=orderItemsRDD.map(lambda x: x.split(',')).map(lambda x: (x[1],float(x[4]))).reduceByKey(lambda acc,value: acc+value).filter(lambda x: x[1]>1000)\nanswerRDD=cancelledOrders.join(itemGreater)\nfor i in answerRDD.take(1) : print i\n"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":["### Find maximum priced product\n1. \"Map\" through the products RDD and stored product price and every product row\n2. Printed using top action"],"metadata":{}},{"cell_type":"code","source":["productsSorted = productsRDD.map(lambda x: (float(x.split(\",\")[3]), x))\n#Top automatically sorts the data in descending order and returns the records, so no need to use it in conjunction with sortByKey\nfor i in productsSorted.top(10): print(i)"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":["### Sort products by price with in each category\n1. \"Map\" through the products RDD and stored category ID and product price\n2. Sorted and printed top proucts by price in each category"],"metadata":{}},{"cell_type":"code","source":["productsParsed = productsRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[1],float(x[3]))).groupByKey()\nsortedProducts = productsParsed.map(lambda (x,y): (x,sorted(y, reverse=True)))\nfor i in sortedProducts.take(2): print(i)"],"metadata":{},"outputs":[],"execution_count":44}],"metadata":{"name":"RetailDataAnalysis_BonusProject","notebookId":3679758509457287},"nbformat":4,"nbformat_minor":0}
